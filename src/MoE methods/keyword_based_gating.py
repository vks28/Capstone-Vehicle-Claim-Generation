# -*- coding: utf-8 -*-
"""Keyword_based_gating.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n7clEqrHr94858oIt1XXFAT4mHEtpTMy
"""

# ==============================
#  Install Required Libraries
# ==============================

!pip install torch torchvision torchaudio
!pip install diffusers transformers accelerate safetensors peft sentence-transformers

# ==============================
# Import Libraries
# ==============================

import torch
from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler
from safetensors.torch import load_file
from collections import OrderedDict
from peft import PeftModel, set_peft_model_state_dict, LoraConfig
from IPython.display import display

# ==============================
# Load Base Stable Diffusion Model
# ==============================

model_id = "runwayml/stable-diffusion-v1-5"
scheduler = EulerAncestralDiscreteScheduler.from_pretrained(model_id, subfolder="scheduler")

pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    scheduler=scheduler,
    torch_dtype=torch.float16
).to("cuda")

# ==============================
# Load LoRA Expert Weights
# ==============================

scratch_state_dict = load_file("capstone-lora-project-1/models1/lora1/scratch_and_gs1/scratch_t4.safetensors")
glass_state_dict = load_file("capstone-lora-project-1/models1/lora1/scratch_and_gs1/gs_t13.safetensors")

# ==============================
# Parse Prompt to Determine Adapter Weights
# ==============================

def get_adapter_weights(prompt):
    """
    Analyze prompt text and assign dynamic weights to LoRA experts
    based on detected damage type and severity keywords.
    """
    expert_keywords = {
        "scratch": ["scratch", "scratches", "scrapes", "deep scratches", "moderate scratches", "light scratch"],
        "glass_shatter": ["glass", "shattered", "shattered glass", "windshield", "cracked",
                          "severe shattered", "moderate shattered", "light shattered"]
    }

    severity_weights = {"light": 0.3, "moderate": 0.7, "severe": 1.0}
    adapter_weights = {"scratch": 0.0, "glass_shatter": 0.0}

    for adapter, keywords in expert_keywords.items():
        for kw in keywords:
            if kw in prompt.lower():
                weight = 0.5  # Default severity if not specified
                for sev, sev_weight in severity_weights.items():
                    if sev in prompt.lower():
                        weight = sev_weight
                        break
                adapter_weights[adapter] = max(adapter_weights[adapter], weight)

    return adapter_weights

# ==============================
# Merge Two Adapter State Dictionaries
# ==============================

def merge_adapters(adapter1, adapter2, w1, w2):
    """
    Linearly combine two adapter state dicts using given weights.
    """
    merged_adapter = OrderedDict()
    for key in adapter1.keys():
        merged_adapter[key] = adapter1[key] * w1 + adapter2[key] * w2
    return merged_adapter

# ==============================
# Apply Merged Adapter to Pipeline
# ==============================

def apply_merged_adapter(pipe, merged_adapter_state_dict):
    """
    Apply merged adapter weights to the UNet model in the pipeline.
    """
    unet_dict = pipe.unet.state_dict()

    for key in merged_adapter_state_dict.keys():
        if key in unet_dict:
            unet_dict[key] += merged_adapter_state_dict[key].to(
                unet_dict[key].device,
                dtype=unet_dict[key].dtype
            )

    pipe.unet.load_state_dict(unet_dict, strict=False)

# ==============================
# Generate Image Based on Prompt
# ==============================

def generate_dynamic_image(prompt, pipe, guidance_scale=7.5, steps=50):
    """
    For a given prompt, determine adapter weights, merge adapters,
    apply them, and generate an image.
    """
    weights = get_adapter_weights(prompt)
    print(f"âœ… Adapter weights: {weights}")

    merged_adapter = merge_adapters(
        scratch_state_dict, glass_state_dict,
        weights["scratch"], weights["glass_shatter"]
    )

    apply_merged_adapter(pipe, merged_adapter)

    image = pipe(prompt, guidance_scale=guidance_scale, num_inference_steps=steps).images[0]
    return image

# ==============================
# Run Generation on Test Prompts
# ==============================

test_prompts = [
    "A black car with light scratches on the front bumper and severe glass shattered on front windshield",
    "A red car with moderate scratches on the front bumper and severe shattered glass on the front windshield.",
    "A red car with severe shattered glass on rear windshield.",
    "A red car with light scratch on rear bumper and moderate shattered glass on rear windshield."
]

for prompt in test_prompts:
    print(f"\nðŸ–¼ Generating for prompt: '{prompt}'")
    img = generate_dynamic_image(prompt, pipe)
    display(img)
    img.save(prompt[:25].replace(" ", "_") + ".png")