# -*- coding: utf-8 -*-
"""TopK_gating&SparseFusion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qEJLQQuOopenErlb0YbQh77rcdy5HAWP
"""

# ================================================
# Import Required Libraries
# ================================================

import numpy as np
import torch
from transformers import CLIPTokenizer, CLIPTextModel
from diffusers import StableDiffusionPipeline

# ================================================
# Top-K Sparse Gating Mechanism
# ================================================

class TopKSparseGating:
    """
    Selects the top-k LoRA experts based on similarity between
    text embeddings and expert gating weights.
    """

    def __init__(self, num_experts=2, embedding_dim=768, clip_model="openai/clip-vit-large-patch14"):
        self.W_g = np.random.rand(num_experts, embedding_dim)  # Random initialization
        self.tokenizer = CLIPTokenizer.from_pretrained(clip_model)
        self.text_encoder = CLIPTextModel.from_pretrained(clip_model)

    def encode_text(self, text_prompt):
        """
        Encode text prompt into CLIP embedding.
        Returns:
            A numpy array of shape (embedding_dim,)
        """
        inputs = self.tokenizer(text_prompt, return_tensors="pt")
        with torch.no_grad():
            embedding = self.text_encoder(**inputs).last_hidden_state.mean(dim=1)
        return embedding.squeeze().numpy()

    def get_expert_scores(self, text_prompt, k=2):
        """
        Scores all experts and returns the top-k based on similarity.
        Returns:
            top_k_indices (list): Selected expert indices.
            top_k_scores (list): Corresponding scores.
        """
        text_embedding = self.encode_text(text_prompt)
        scores = np.dot(self.W_g, text_embedding)  # Similarity score

        # Normalize scores to [0, 1]
        scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))

        # Get top-k experts
        top_k_indices = np.argsort(scores)[-k:]
        top_k_scores = scores[top_k_indices]

        return top_k_indices, top_k_scores

# ================================================
# Sparse Fusion Mechanism
# ================================================

class SparseFusion:
    """
    Suppresses weaker experts unless scores are balanced.
    Prioritizes one dominant expert if significantly stronger.
    """

    def __init__(self, threshold=0.7):
        self.threshold = threshold

    def fuse_expert_weights(self, scores):
        """
        Given scores of top-k experts, apply sparse weighting.
        Returns:
            sparse_weights (list): Final normalized weights.
        """
        max_score = max(scores)
        min_score = min(scores)
        score_diff = max_score - min_score

        print(f"Max Score: {max_score}, Min Score: {min_score}, Difference: {score_diff}")

        if max_score > self.threshold or score_diff > 0.4:
            print("ðŸ”´ Condition Satisfied! Keeping only the dominant expert.")
            sparse_weights = [1.0 if s == max_score else 0.0 for s in scores]
        else:
            print("ðŸŸ¢ Condition NOT satisfied. Normalizing both expert scores.")
            sparse_weights = scores / sum(scores)

        print(f"Final Weights: {sparse_weights}")
        return sparse_weights

# ================================================
# LoRA Expert Loader
# ================================================

class LoRAExpertLoader:
    """
    Loads LoRA weights dynamically based on selected experts.
    Automatically maps index to predefined paths.
    """

    def __init__(self):
        self.lora_paths = {
            0: "scratch/adapter_model.safetensors",     # Scratch Expert
            1: "gs/adapter_model.safetensors"           # Glass Shatter Expert
        }

    def apply_lora_weights(self, pipe, selected_experts, final_weights):
        """
        Apply weighted LoRA adapters into the Stable Diffusion pipeline.
        Returns:
            Updated pipeline.
        """
        for i, expert_index in enumerate(selected_experts):
            if final_weights[i] > 0:
                pipe.load_lora_weights(self.lora_paths[expert_index], weight=final_weights[i])
        return pipe

# ================================================
# Running the Expert Selection and Generation
# ================================================

# Step 1: Define the input prompt
text_prompt = "A red coloured car with a light scratch on the front bumper"

# Step 2: Initialize gating mechanism and select experts
gating_mechanism = TopKSparseGating(num_experts=2)
selected_experts, selected_scores = gating_mechanism.get_expert_scores(text_prompt, k=2)

print("Selected Experts:", selected_experts)
print("Selected Scores:", selected_scores)

# Step 3: Initialize fusion mechanism and calculate sparse weights
combination_mechanism = SparseFusion(threshold=0.7)
final_weights = combination_mechanism.fuse_expert_weights(selected_scores)
print("Final Weights:", final_weights)

# Step 4: Load Stable Diffusion base model
pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")

# Step 5: Load and apply selected LoRA expert weights
lora_loader = LoRAExpertLoader()
pipe = lora_loader.apply_lora_weights(pipe, selected_experts, final_weights)

# Step 6: Generate and show final image
image = pipe(prompt=text_prompt).images[0]
image.show()